# -*- coding: utf-8 -*-
"""Env._1-Limpieza Datos y Feature Predicción de la pérdida de clientes bancarios.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dTC_eyjF5PaKuscDm15Rn5AwSfxWqXzf

## **Reto Data Science (DS) y Machine Learning (ML): Proyecto**
- Semana 3: Procesamiento datos
- Semana 4: Entrenar, seleccionar y optimizar modelos ML

# Indice proyecto:
* **0- Datos + EDA Predicción de la pérdida de clientes bancarios**
  * Link: https://colab.research.google.com/drive/1M1lqHtNfYDXLTSj7hKdnb3CjdM2pck0H?usp=sharing

* **1-Limpieza Datos y Feature Predicción de la pérdida de clientes bancarios**
    * Link:https://colab.research.google.com/drive/1dTC_eyjF5PaKuscDm15Rn5AwSfxWqXzf?usp=sharing

**Nota**: Al inicio del proyecto se  guardo el archivo original con nombre *Churn_Modelling_Original.csv* en local y se continúa trabajando con la copia del archivo llamada *Seg_Clientes.csv.*

# Resumen proceso de limpieza y entrenamiento.

**1. Objetivo del proyecto**

Predecir qué clientes van a abandonar el banco (variable Exited = 1), utilizando un modelo de clasificación. El foco está en identificar a los clientes en riesgo para prevenir su fuga.

**2. Preparación y limpieza de datos**

- Se eliminaron columnas sin valor predictivo: RowNumber, CustomerId, Surname.
- Se imputaron valores nulos en Age, HasCrCard e IsActiveMember.
- Se codificaron variables categóricas (Gender → 0/1 y Geography → dummies).
- Se aplicó winsorización a Age y CreditScore para evitar que valores extremos afecten al modelo.

**3. División de datos**

- Se separaron los datos en entrenamiento (80%) y prueba (20%) con estratificación.
- Se aplicó SMOTE sobre el conjunto de entrenamiento para balancear las clases (fugas vs no fugas).
- Esto garantiza que el modelo no aprenda solo a identificar a los que no se van, ya que esa clase es mayoritaria.

**4. Evaluación de modelos**

- Se evaluaron 10 modelos de clasificación, Accuracy,F1-Score	Recall, ROC AUC, etc.
- Los modelos fueron evaluados con validación cruzada de 5 particiones, y se eligieron los mejores según F1-score y ROC AUC, que son las métricas más relevantes cuando hay clases desbalanceadas.

**5. Entrenamiento final y ajuste de umbral**

- Se entrenaron nuevamente los 3 mejores modelos y se ajustó su umbral de clasificación para mejorar el F1-score.

- **Gradient Boosting** fue elegido como modelo final, ya que ofreció el mejor equilibrio entre precisión y recall, maximizando el F1-score con una excelente precisión general (86%).

**6. Interpretabilidad del modelo con SHAP**

- Se utilizó la librería SHAP para interpretar el modelo.
- Se generó un gráfico que muestra qué variables afectan más a la decisión del modelo.
- Por ejemplo: Age, Balance y NumOfProducts fueron claves para decidir si un cliente se va o no.

**Decisión final y toma de acción**

- Modelo elegido: Gradient Boosting
- Mejor porcentaje de detección de fuga (Recall): 62%
- F1-score optimizado: 64%
- Precisión general (Accuracy): 86%
- Esto significa que de cada 100 clientes que se iban a ir, el modelo identifica correctamente a 62.

# Conclusión del proyecto: Predicción de fuga de clientes

Se desarrolló un sistema de machine learning para anticipar la fuga de clientes bancarios. Tras evaluar 10 modelos, Gradient Boosting fue el mejor, logrando un F1-score de 0.64 y un recall del 62%. El modelo permite detectar clientes en riesgo de forma precisa y explicable, y está listo para aplicarse con nuevos datos en acciones de retención.
"""

#@title **Importación de librerías para análisis, modelos y métricas**

# Manipulación de datos
import pandas as pd  # Procesar, analizar y limpiar datos
import numpy as np  # Operaciones matemáticas y manipulación de matrices

# Visualización
import seaborn as sns  # Visualización de datos con gráficos estadísticos
import matplotlib.pyplot as plt  # Generación de gráficos y visualización de datos

# Instalar y cargar la librería para generar EDA automático (Exploratory Data Analysis)
#!pip install ydata-profiling
#from ydata_profiling import ProfileReport  # Creación automática de reportes de análisis de datos

# Preprocesamiento y métricas
# Importar la librería para dividir el conjunto de datos en entrenamiento y prueba
from sklearn.model_selection import train_test_split, cross_validate # División en Train y Test # Evaluación de modelos con validación cruzada
from sklearn.metrics import classification_report, precision_recall_curve

# Importar el escalador para la estandarización de variables (Feature Scaling)
from sklearn.preprocessing import StandardScaler  # Normalización de datos para mejorar el rendimiento de los modelos

# Balanceo de clases
# Instalar y cargar la librería SMOTE para oversampling en conjuntos de datos desbalanceados
!pip install imbalanced-learn
from imblearn.over_sampling import SMOTE  # Generación de datos sintéticos para balancear clases desbalanceadas
from collections import Counter  # Contar cuántos ejemplos hay por clase
from imblearn.pipeline import Pipeline as ImbPipeline  # Pipeline que soporta SMOTE


# Importar modelos de Machine Learning
!pip install xgboost lightgbm scikit-learn pandas
from sklearn.linear_model import LogisticRegression  # Modelo de clasificación lineal
from sklearn.tree import DecisionTreeClassifier  # Árbol de decisión para clasificación
from sklearn.ensemble import RandomForestClassifier  # Ensamble de árboles para mejorar precisión
from sklearn.ensemble import GradientBoostingClassifier  # Modelo de ensamble basado en boosting
from xgboost import XGBClassifier  # Variante optimizada de boosting (muy eficiente y precisa)
from lightgbm import LGBMClassifier  # Variante rápida de boosting (especial para grandes datasets)
from sklearn.svm import SVC  # Clasificador basado en Support Vector Machines (SVM)
from sklearn.neighbors import KNeighborsClassifier  # Clasificación basada en proximidad (distancias entre puntos)
from sklearn.naive_bayes import GaussianNB  # Clasificador basado en probabilidad condicional (ideal para texto y datos simples)
from sklearn.neural_network import MLPClassifier  # Red neuronal multicapa (Multi-Layer Perceptron)
from sklearn.ensemble import VotingClassifier

import lightgbm as lgb

# Importar librerías para Grid Search (búsqueda de hiperparámetros óptimos)
from sklearn.model_selection import GridSearchCV  # Búsqueda de hiperparámetros óptimos en modelos

# Métricas para evaluar modelos de clasificación
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import (
    roc_auc_score,  # Área bajo la curva ROC (para evaluar modelos de clasificación)
    accuracy_score,  # Exactitud del modelo (porcentaje de predicciones correctas)
    precision_score,  # Precisión (proporción de verdaderos positivos sobre los predichos como positivos)
    recall_score,  # Recall o sensibilidad (proporción de verdaderos positivos sobre todos los positivos reales)
    f1_score,  # F1-score (combinación de precisión y recall, útil para datos desbalanceados)
    precision_recall_curve  # Calcula la curva de precisión-recall, útil en datos desbalanceados
)

# Instalar e importar SHAP para interpretabilidad de modelos
!pip install shap
import shap  # Análisis de importancia de características en modelos de Machine Learning

# Importar librerías para creación de pipelines
from sklearn.pipeline import Pipeline  # Creación de flujos de trabajo automatizados para preprocesamiento y modelado

# Crear transformadores personalizados
from sklearn.base import BaseEstimator, TransformerMixin

print("Librerías cargadas correctamente.")

#@title Cargar datos perdida_clientes

# 0. Cargar datos desde CSV (usar comando para leer el CSV descargado y guardado en el Colab).
df_Seg_Clientes = pd.read_csv("Seg_Clientes.csv")

#@title Guardar Carga de Datos (cargar_csv.py)
codigo_cargar_csv = """
import pandas as pd

def cargar_datos(ruta_csv):
    \"\"\"Carga el dataset desde un archivo CSV y lo retorna como DataFrame.\"\"\"
    df = pd.read_csv(ruta_csv)
    return df
"""

with open("cargar_csv.py", "w") as f:
    f.write(codigo_cargar_csv)

from google.colab import files
files.download("cargar_csv.py")

#@title Cargar y limpieza de datos perdida_clientes

# 0. Cargar datos desde CSV (usar comando para leer el CSV descargado y guardado en el Colab).
df_Seg_Clientes = pd.read_csv("Seg_Clientes.csv")

# 1. Eliminar columnas innecesarias y limpiar duplicados o nulos en 'Geography'

def limpiar_datos(df):
    df = df.copy()

    # Eliminar columnas irrelevantes
    df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)

    # Eliminar duplicados y nulos
    df.drop_duplicates(inplace=True)
    df.dropna(subset=['Geography'], inplace=True)

    # Imputar valores faltantes
    df['Age'] = df['Age'].fillna(df['Age'].mean())
    df['HasCrCard'] = df['HasCrCard'].fillna(df['HasCrCard'].mode()[0])
    df['IsActiveMember'] = df['IsActiveMember'].fillna(df['IsActiveMember'].mode()[0])


    # Codificar 'Gender' como 0 (Male) y 1 (Female)
    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})

    # One-hot encoding para 'Geography' (con drop_first para evitar multicolinealidad)
    df = pd.get_dummies(df, columns=['Geography'], drop_first=True)

    # Convertir columnas booleanas (si las hay) a enteros (0 y 1)
    # Esto asegura que columnas como geography no aparezcan como True/False
    bool_cols = df.select_dtypes(include='bool').columns
    df[bool_cols] = df[bool_cols].astype(int)

    return df

    # Aplicar la limpieza
df_limpio = limpiar_datos(df_Seg_Clientes)

#@title Guardar el archivo como limpieza_datos.py
codigo_limpieza = """
import pandas as pd

def limpiar_datos(df):
    df = df.copy()
    df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)
    df.drop_duplicates(inplace=True)
    df.dropna(subset=['Geography'], inplace=True)

    df['Age'] = df['Age'].fillna(df['Age'].mean())
    df['HasCrCard'] = df['HasCrCard'].fillna(df['HasCrCard'].mode()[0])
    df['IsActiveMember'] = df['IsActiveMember'].fillna(df['IsActiveMember'].mode()[0])

    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})
    df = pd.get_dummies(df, columns=['Geography'], drop_first=True)

    bool_cols = df.select_dtypes(include='bool').columns
    df[bool_cols] = df[bool_cols].astype(int)

    return df
"""

# Guardar el archivo como limpieza_datos.py
with open("limpieza_datos.py", "w") as f:
    f.write(codigo_limpieza)

# Descargar el archivo desde Colab
from google.colab import files
files.download("limpieza_datos.py")

#@title Analizar correlaciones con la variable objetivo 'Exited'
correlaciones = df_limpio.corr()['Exited'].drop('Exited').sort_values(ascending=False)

print("Correlaciones con la variable 'Exited':")
print(correlaciones)

# Visualización como mapa de calor

# Convertir a DataFrame para usar heatmap
correlaciones_df = correlaciones.to_frame().T

plt.figure(figsize=(10, 1.5))
sns.heatmap(correlaciones_df, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlaciones de variables con 'Exited'")
plt.yticks(rotation=0)
#plt.tight_layout()
plt.show()

#@title División de variable Exited
# X: Variables predictoras / y: Variable objetivo
X = df_limpio.drop("Exited", axis=1)
y = df_limpio["Exited"]

# División en conjunto de entrenamiento (80%) y prueba (20%)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

#@title Guardar División de Datos (division_datos.py)
codigo_division_datos = """
from sklearn.model_selection import train_test_split

def dividir_datos(df):
    X = df.drop("Exited", axis=1)
    y = df["Exited"]
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )
    return X_train, X_test, y_train, y_test
"""

with open("division_datos.py", "w") as f:
    f.write(codigo_division_datos)

from google.colab import files
files.download("division_datos.py")

#@title Class para aplicar winsorización a columnas numéricas (recorta valores extremos Outliers)

class Winsorizer(BaseEstimator, TransformerMixin):
    def __init__(self, columns=None, lower=0.01, upper=0.99):
        self.columns = columns
        self.lower = lower
        self.upper = upper

    def fit(self, X, y=None):
        self.bounds_ = {
            col: (X[col].quantile(self.lower), X[col].quantile(self.upper))
            for col in self.columns
        }
        return self

    def transform(self, X):
        X = X.copy()
        for col, (low, high) in self.bounds_.items():
            X[col] = X[col].clip(lower=low, upper=high)
        return X

#@title Guardar Winsorizer (winsorizer.py)
codigo_winsorizer = """
import numpy as np
from sklearn.base import BaseEstimator, TransformerMixin

class Winsorizer(BaseEstimator, TransformerMixin):
    def __init__(self, columns=None, lower=0.01, upper=0.99):
        self.columns = columns
        self.lower = lower
        self.upper = upper

    def fit(self, X, y=None):
        self.bounds_ = {col: (X[col].quantile(self.lower), X[col].quantile(self.upper)) for col in self.columns}
        return self

    def transform(self, X):
        X = X.copy()
        for col, (low, high) in self.bounds_.items():
            X[col] = X[col].clip(lower=low, upper=high)
        return X
"""

with open("winsorizer.py", "w") as f:
    f.write(codigo_winsorizer)

from google.colab import files
files.download("winsorizer.py")

#@title Evaluación de todos los modelos con Pipeline
# Definir modelos: Diccionario con los principales modelos de clasificación
modelos = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "LightGBM": LGBMClassifier(random_state=42),
    "SVM": SVC(probability=True, random_state=42),
    "KNN": KNeighborsClassifier(),
    "Naive Bayes": GaussianNB(),
    "MLP": MLPClassifier(max_iter=300, random_state=42)
}

#Definir métricas a evaluar
# Métricas comunes para clasificación
scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']

# Evaluar cada modelo con el mismo pipeline (winsor + SMOTE + escalado + modelo)
resultados = []

for nombre, modelo in modelos.items():
    print(f"Evaluando: {nombre}")

    pipe = ImbPipeline(steps=[
        ('winsor', Winsorizer(columns=['Age', 'CreditScore'])),
        ('smote', SMOTE(random_state=42)),
        ('scaler', StandardScaler()),
        ('model', modelo)
    ])

    scores = cross_validate(pipe, X_train, y_train, scoring=scoring, cv=5)

    resultados.append({
        'Modelo': nombre,
        'Accuracy': np.mean(scores['test_accuracy']),
        'Precision': np.mean(scores['test_precision']),
        'Recall': np.mean(scores['test_recall']),
        'F1 Score': np.mean(scores['test_f1']),
        'ROC AUC': np.mean(scores['test_roc_auc'])
    })
# Crear y mostrar tabla ordenada por ROC AUC
df_resultados = pd.DataFrame(resultados).sort_values(by='ROC AUC', ascending=False).reset_index(drop=True)
print("\n Resultados de validación cruzada:")
print(df_resultados)

#@title Guardar Evaluación de Modelos (evaluacion_modelos.py)
codigo_evaluacion = """
import numpy as np
import pandas as pd
from sklearn.model_selection import cross_validate
from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from lightgbm import LGBMClassifier

def evaluar_modelos(X_train, y_train):
    modelos = {
        "Gradient Boosting": GradientBoostingClassifier(random_state=42),
        "LightGBM": LGBMClassifier(random_state=42),
        "Random Forest": RandomForestClassifier(random_state=42, class_weight='balanced')
    }

    scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']
    resultados = []

    for nombre, modelo in modelos.items():
        pipe = ImbPipeline(steps=[
            ('winsor', Winsorizer(columns=['Age', 'CreditScore'])),
            ('smote', SMOTE(random_state=42)),
            ('scaler', StandardScaler()),
            ('model', modelo)
        ])
        scores = cross_validate(pipe, X_train, y_train, scoring=scoring, cv=5)

        resultados.append({
            'Modelo': nombre,
            'Accuracy': np.mean(scores['test_accuracy']),
            'Precision': np.mean(scores['test_precision']),
            'Recall': np.mean(scores['test_recall']),
            'F1 Score': np.mean(scores['test_f1']),
            'ROC AUC': np.mean(scores['test_roc_auc'])
        })

    return pd.DataFrame(resultados).sort_values(by='ROC AUC', ascending=False).reset_index(drop=True)
"""

with open("evaluacion_modelos.py", "w") as f:
    f.write(codigo_evaluacion)

from google.colab import files
files.download("evaluacion_modelos.py")

#@title Preparar modelos finalistas
# Modelos seleccionados por mejor desempeño en ROC AUC y F1 Score
finalistas = {
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "LightGBM": LGBMClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42, class_weight='balanced')
}

# Evaluar cada modelo con ajuste de umbral
from sklearn.metrics import precision_recall_curve

for nombre, modelo in finalistas.items():
    print(f"\n Entrenando y evaluando: {nombre}")

    # Pipeline completo: Winsorización + SMOTE + Escalado + Modelo
    pipeline = ImbPipeline(steps=[
        ('winsor', Winsorizer(columns=['Age', 'CreditScore'])),
        ('smote', SMOTE(random_state=42)),
        ('scaler', StandardScaler()),
        ('model', modelo)
    ])

    # Entrenar con todo el conjunto de entrenamiento
    pipeline.fit(X_train, y_train)

    # Obtener probabilidades para clase positiva
    y_probs = pipeline.predict_proba(X_test)[:, 1]

    # Calcular curvas de precision y recall para distintos umbrales
    prec, rec, thresholds = precision_recall_curve(y_test, y_probs)

    # Calcular F1-score para cada umbral
    f1_scores = 2 * (prec * rec) / (prec + rec + 1e-8)

    # Elegir el umbral con mejor F1-score
    best_idx = f1_scores.argmax()
    best_threshold = thresholds[best_idx]

    print(f" Mejor umbral por F1-score: {best_threshold:.3f}")

    # Predecir clases con el mejor umbral
    y_pred_ajustado = (y_probs >= best_threshold).astype(int)

    # Mostrar informe de clasificación
    print("\n Informe de clasificación final:")
    print(classification_report(y_test, y_pred_ajustado))

# Visualizar cómo cambian precisión y recall con el umbral (para el último modelo evaluado)

plt.figure(figsize=(10, 6))
plt.plot(thresholds, prec[:-1], label='Precisión', linestyle='--')
plt.plot(thresholds, rec[:-1], label='Recall', linestyle='-')
plt.xlabel("Umbral de decisión")
plt.ylabel("Valor")
plt.title("Curva Precisión vs Recall según umbral")
plt.legend()
plt.grid(True)
plt.show()

#@title Guardar Selección del Mejor Modelo (seleccion_modelo.py)
codigo_seleccion_modelo = """
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, classification_report
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from lightgbm import LGBMClassifier

def seleccionar_mejor_modelo(X_train, X_test, y_train, y_test):
    finalistas = {
        "Gradient Boosting": GradientBoostingClassifier(random_state=42),
        "LightGBM": LGBMClassifier(random_state=42),
        "Random Forest": RandomForestClassifier(random_state=42, class_weight='balanced')
    }

    for nombre, modelo in finalistas.items():
        print(f"\n Entrenando y evaluando: {nombre}")

        pipeline = ImbPipeline(steps=[
            ('winsor', Winsorizer(columns=['Age', 'CreditScore'])),
            ('smote', SMOTE(random_state=42)),
            ('scaler', StandardScaler()),
            ('model', modelo)
        ])

        pipeline.fit(X_train, y_train)
        y_probs = pipeline.predict_proba(X_test)[:, 1]
        prec, rec, thresholds = precision_recall_curve(y_test, y_probs)
        f1_scores = 2 * (prec * rec) / (prec + rec + 1e-8)
        best_threshold = thresholds[f1_scores.argmax()]
        print(f" Mejor umbral por F1-score: {best_threshold:.3f}")

        y_pred_ajustado = (y_probs >= best_threshold).astype(int)
        print("\n Informe de clasificación final:")
        print(classification_report(y_test, y_pred_ajustado))

        plt.figure(figsize=(10, 6))
        plt.plot(thresholds, prec[:-1], label='Precisión', linestyle='--')
        plt.plot(thresholds, rec[:-1], label='Recall', linestyle='-')
        plt.xlabel("Umbral de decisión")
        plt.ylabel("Valor")
        plt.title("Curva Precisión vs Recall según umbral")
        plt.legend()
        plt.grid(True)
        plt.show()
"""

with open("seleccion_modelo.py", "w") as f:
    f.write(codigo_seleccion_modelo)

from google.colab import files
files.download("seleccion_modelo.py")

#@title Guardar el mejor modelo
import joblib

# Entrenar pipeline final con Gradient Boosting
final_pipeline = ImbPipeline(steps=[
    ('winsor', Winsorizer(columns=['Age', 'CreditScore'])),
    ('smote', SMOTE(random_state=42)),
    ('scaler', StandardScaler()),
    ('model', GradientBoostingClassifier(random_state=42))
])

final_pipeline.fit(X_train, y_train)

# Guardar el pipeline entrenado
joblib.dump(final_pipeline, 'modelo_fuga_clientes.pkl')

# Extraer el escalador desde el pipeline
scaler = final_pipeline.named_steps['scaler']

# Guardar el escalador
joblib.dump(scaler, "scaler_robust_fuga_clientes.pkl")

print("Modelo y escalador guardados correctamente en el entorno de trabajo.")

#@title Usar el modelo con nuevos datos
# Cargar modelo entrenado
modelo_cargado = joblib.load('modelo_fuga_clientes.pkl')

# Simular nuevos datos (misma estructura que X_test)
nuevo_cliente = X_test.iloc[[0]]

# Predecir la probabilidad de fuga
prob_fuga = modelo_cargado.predict_proba(nuevo_cliente)[:, 1][0]
print(f"Probabilidad de fuga: {prob_fuga:.2f}")

# Aplicar umbral ajustado
if prob_fuga >= 0.475:  # umbral óptimo para Gradient Boosting
    print("⚠️ Cliente con riesgo de fuga.")
else:
    print("✅ Cliente sin riesgo de fuga.")

#@title Guardar Predicción con Nuevo Cliente (prediccion_nuevo.py)
codigo_prediccion_nuevo = """
import joblib
import pandas as pd

def predecir_cliente(X_test, modelo_path="modelo_fuga_clientes.pkl", scaler_path="scaler_robust_fuga_clientes.pkl", umbral=0.475):
    \"\"\"Carga el modelo y escalador guardados, luego predice si un nuevo cliente está en riesgo de fuga.\"\"\"
    modelo = joblib.load(modelo_path)
    scaler = joblib.load(scaler_path)

    nuevo_cliente = X_test.iloc[[0]]  # Simulación de un nuevo cliente
    nuevo_cliente_escalado = scaler.transform(nuevo_cliente)

    prob_fuga = modelo.predict_proba(nuevo_cliente_escalado)[:, 1][0]
    resultado = "⚠️ Cliente con riesgo de fuga." if prob_fuga >= umbral else "✅ Cliente sin riesgo de fuga."

    return prob_fuga, resultado
"""

with open("prediccion_nuevo.py", "w") as f:
    f.write(codigo_prediccion_nuevo)

from google.colab import files
files.download("prediccion_nuevo.py")

#@title Interpretar el modelo con SHAP

# Paso 1: Extraer pasos del pipeline entrenado
winsor = final_pipeline.named_steps['winsor']
scaler = final_pipeline.named_steps['scaler']

# Paso 2: Aplicar winsorización y escalado manualmente al conjunto de test
X_test_winsor = winsor.transform(X_test)
X_test_scaled = scaler.transform(X_test_winsor)

# Paso 3: Convertir los datos escalados a DataFrame con nombres originales
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)

# Paso 4: Crear el explainer de SHAP con el modelo final y los datos preprocesados
explainer = shap.Explainer(final_pipeline.named_steps['model'], X_test_scaled)
shap_values = explainer(X_test_scaled)

# Paso 5: Visualizar importancia de características con gráfico SHAP
shap.plots.beeswarm(shap_values)

#@title Guardar Interpretación con SHAP (interpretacion_shap.py)
codigo_interpretacion_shap = """
import shap
import joblib
import pandas as pd

def interpretar_modelo(X_test, modelo_path="modelo_fuga_clientes.pkl", scaler_path="scaler_robust_fuga_clientes.pkl"):
    \"\"\"Carga el modelo y el escalador, transforma los datos, y genera visualizaciones SHAP.\"\"\"
    modelo = joblib.load(modelo_path)
    scaler = joblib.load(scaler_path)

    X_test_scaled = scaler.transform(X_test)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)

    explainer = shap.Explainer(modelo, X_test_scaled)
    shap_values = explainer(X_test_scaled)

    shap.summary_plot(shap_values, X_test_scaled)  # Visualización global
    shap.plots.beeswarm(shap_values)  # Impacto individual de cada característica
"""

with open("interpretacion_shap.py", "w") as f:
    f.write(codigo_interpretacion_shap)

from google.colab import files
files.download("interpretacion_shap.py")